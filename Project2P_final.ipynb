{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOV3c2rQjEzOCNRYdV3PmVS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/deepw98/project2/blob/main/Project2P_final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jDqpF8ZOyJ6K",
        "outputId": "b9dc9964-70bb-484a-a18e-bbb817cb0aaf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r /content/drive/MyDrive/fire_detection_few_shot /content/fire_detection_few_shot"
      ],
      "metadata": {
        "id": "-qYL8n2ryXFO"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.manifold import TSNE\n",
        "from tensorflow.keras.applications import EfficientNetB0\n",
        "from tensorflow.keras.layers import Dense, Flatten, Lambda, Input\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
        "import pickle\n"
      ],
      "metadata": {
        "id": "kb0JLZr6yvHD"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_and_preprocess_image(img_path, target_size=(224, 224)):\n",
        "    img = tf.keras.preprocessing.image.load_img(img_path, target_size=target_size)\n",
        "    img = tf.keras.preprocessing.image.img_to_array(img) / 255.0\n",
        "    return img"
      ],
      "metadata": {
        "id": "5mYnLbKAy3rH"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_dataset(dataset_path, batch_size=32, img_size=(224, 224)):\n",
        "    dataset = image_dataset_from_directory(\n",
        "        dataset_path,\n",
        "        image_size=img_size,\n",
        "        batch_size=batch_size\n",
        "    )\n",
        "    return dataset\n"
      ],
      "metadata": {
        "id": "bC_ZCzEKy_XG"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_feature_extractor():\n",
        "    base_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "    base_model.trainable = False\n",
        "    inputs = Input(shape=(224, 224, 3))\n",
        "    x = base_model(inputs, training=False)\n",
        "    x = Flatten()(x)\n",
        "    outputs = Dense(128, activation=None)(x)\n",
        "    model = Model(inputs, outputs)\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "eG6Rz0hCzFfe"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pairwise_distances(embeddings):\n",
        "    return tf.norm(tf.expand_dims(embeddings, axis=1) - tf.expand_dims(embeddings, axis=0), axis=-1)\n"
      ],
      "metadata": {
        "id": "6EoiU7Hb42JO"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def hard_pair_mining(embeddings, labels):\n",
        "    distances = pairwise_distances(embeddings)\n",
        "    pos_mask = tf.equal(tf.expand_dims(labels, axis=1), tf.expand_dims(labels, axis=0))\n",
        "    neg_mask = tf.logical_not(pos_mask)\n",
        "\n",
        "    hardest_positive = tf.reduce_max(tf.where(pos_mask, distances, tf.zeros_like(distances)), axis=1)\n",
        "    hardest_negative = tf.reduce_min(tf.where(neg_mask, distances, tf.fill(tf.shape(distances), tf.float32.max)), axis=1)\n",
        "    return hardest_positive, hardest_negative\n"
      ],
      "metadata": {
        "id": "L3qEp0wFzKWO"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sample_episode(dataset, n_way=5, k_shot=5, q_queries=5):\n",
        "    \"\"\"Samples an episode with N classes, K support samples, and Q query samples.\"\"\"\n",
        "    class_indices = list(dataset.class_names)\n",
        "    selected_classes = random.sample(class_indices, n_way)\n",
        "\n",
        "    support_set = []\n",
        "    query_set = []\n",
        "\n",
        "    for cls in selected_classes:\n",
        "        cls_images = [img for img, label in dataset if dataset.class_names[label] == cls]\n",
        "        sampled_images = random.sample(cls_images, k_shot + q_queries)\n",
        "        support_set.extend(sampled_images[:k_shot])\n",
        "        query_set.extend(sampled_images[k_shot:])\n",
        "\n",
        "    return support_set, query_set, selected_classes"
      ],
      "metadata": {
        "id": "PfIGSpWyFSPG"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_prototypes(support_set, feature_extractor):\n",
        "    \"\"\"Computes class prototypes by averaging support embeddings.\"\"\"\n",
        "    support_embeddings = feature_extractor(support_set)\n",
        "    prototypes = []\n",
        "\n",
        "    for i in range(len(support_set) // len(set(support_set.labels))):\n",
        "        cls_embeddings = support_embeddings[i * len(set(support_set.labels)):(i+1) * len(set(support_set.labels))]\n",
        "        prototypes.append(tf.reduce_mean(cls_embeddings, axis=0))\n",
        "\n",
        "    return tf.stack(prototypes)"
      ],
      "metadata": {
        "id": "uIEJTiB_FUut"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prototypical_loss(y_true, embeddings):\n",
        "    hardest_positive, hardest_negative = hard_pair_mining(embeddings, y_true)\n",
        "    loss = tf.maximum(hardest_positive - hardest_negative + 0.2, 0.0)\n",
        "    return tf.reduce_mean(loss)"
      ],
      "metadata": {
        "id": "5CSgGkrezPLk"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prototypical_loss(prototypes, query_embeddings, query_labels):\n",
        "    \"\"\"Computes the loss based on distance of query samples from prototypes.\"\"\"\n",
        "    distances = tf.norm(query_embeddings[:, None, :] - prototypes[None, :, :], axis=-1)\n",
        "    predictions = tf.argmin(distances, axis=-1)\n",
        "    loss = tf.keras.losses.sparse_categorical_crossentropy(query_labels, predictions)\n",
        "    return loss"
      ],
      "metadata": {
        "id": "7pIwG0UYFhLD"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_prototypical_network(dataset, feature_extractor, epochs=10, n_way=5, k_shot=5, q_queries=5):\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        episode_loss = 0\n",
        "\n",
        "        for _ in range(len(dataset) // (n_way * (k_shot + q_queries))):\n",
        "            support_set, query_set, selected_classes = sample_episode(dataset, n_way, k_shot, q_queries)\n",
        "\n",
        "            with tf.GradientTape() as tape:\n",
        "                prototypes = compute_prototypes(support_set, feature_extractor)\n",
        "                query_embeddings = feature_extractor(query_set)\n",
        "                query_labels = [selected_classes.index(cls) for cls in query_set.labels]\n",
        "                loss = prototypical_loss(prototypes, query_embeddings, query_labels)\n",
        "\n",
        "            gradients = tape.gradient(loss, feature_extractor.trainable_variables)\n",
        "            optimizer.apply_gradients(zip(gradients, feature_extractor.trainable_variables))\n",
        "            episode_loss += loss.numpy()\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {episode_loss/len(dataset)}\")\n"
      ],
      "metadata": {
        "id": "4d47A40hFpBD"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def train_model(dataset_path, epochs=10, save_path=\"embeddings.pkl\"):\n",
        "#     dataset = load_dataset(dataset_path)\n",
        "#     feature_extractor = create_feature_extractor()\n",
        "#     optimizer = Adam(learning_rate=0.001)\n",
        "\n",
        "#     all_embeddings = {}\n",
        "\n",
        "#     for epoch in range(epochs):\n",
        "#         epoch_loss = 0\n",
        "#         epoch_embeddings = []\n",
        "#         epoch_labels = []\n",
        "\n",
        "#         for images, labels in dataset:\n",
        "#             with tf.GradientTape() as tape:\n",
        "#                 embeddings = feature_extractor(images)\n",
        "#                 loss = prototypical_loss(labels, embeddings)\n",
        "\n",
        "#             gradients = tape.gradient(loss, feature_extractor.trainable_variables)\n",
        "#             optimizer.apply_gradients(zip(gradients, feature_extractor.trainable_variables))\n",
        "\n",
        "#             epoch_loss += loss.numpy()\n",
        "#             epoch_embeddings.append(embeddings.numpy())\n",
        "#             epoch_labels.append(labels.numpy())\n",
        "\n",
        "#         print(f\"Epoch {epoch+1}/{epochs}, Loss: {epoch_loss / len(dataset)}\")\n",
        "\n",
        "#         all_embeddings[epoch + 1] = {\n",
        "#             \"embeddings\": np.concatenate(epoch_embeddings, axis=0),\n",
        "#             \"labels\": np.concatenate(epoch_labels, axis=0),\n",
        "#         }\n",
        "\n",
        "#     with open(save_path, \"wb\") as f:\n",
        "#         pickle.dump(all_embeddings, f)\n",
        "#     print(f\"Embeddings saved to {save_path}\")\n",
        "\n",
        "#     return feature_extractor  # Return trained model\n",
        "\n",
        "# # Train and get model\n",
        "# feature_extractor = train_model(\"/content/fire_detection_few_shot/train\")\n"
      ],
      "metadata": {
        "id": "UY2HKEJAzUbg"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train_model(\"/content/fire_detection_few_shot/train\")"
      ],
      "metadata": {
        "id": "R8abCjz57qTo"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset\n",
        "dataset_path = \"/content/fire_detection_few_shot/train\"\n",
        "dataset = load_dataset(dataset_path)\n",
        "\n",
        "# Create feature extractor\n",
        "feature_extractor = create_feature_extractor()\n",
        "\n",
        "# Train the prototypical network\n",
        "train_prototypical_network(dataset, feature_extractor, epochs=10, n_way=5, k_shot=5, q_queries=5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "661hL460Gth3",
        "outputId": "dfe80910-5ee8-4116-dec7-9c66da26d78d"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 294 files belonging to 2 classes.\n",
            "Epoch 1/10, Loss: 0.0\n",
            "Epoch 2/10, Loss: 0.0\n",
            "Epoch 3/10, Loss: 0.0\n",
            "Epoch 4/10, Loss: 0.0\n",
            "Epoch 5/10, Loss: 0.0\n",
            "Epoch 6/10, Loss: 0.0\n",
            "Epoch 7/10, Loss: 0.0\n",
            "Epoch 8/10, Loss: 0.0\n",
            "Epoch 9/10, Loss: 0.0\n",
            "Epoch 10/10, Loss: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sample_episode(dataset, n_way=2, k_shot=5, q_queries=5):\n",
        "    \"\"\"Samples an episode with dynamic k_shot and q_queries based on available images.\"\"\"\n",
        "    class_indices = dataset.class_names\n",
        "    selected_classes = random.sample(class_indices, min(n_way, len(class_indices)))\n",
        "\n",
        "    # Convert dataset to a list of (image, label) pairs\n",
        "    all_images = []\n",
        "    all_labels = []\n",
        "    for batch_images, batch_labels in dataset:\n",
        "        for img, label in zip(batch_images, batch_labels.numpy()):  # Convert labels to NumPy scalars\n",
        "            all_images.append(img)\n",
        "            all_labels.append(int(label))  # Ensure labels are integers\n",
        "\n",
        "    support_set = []\n",
        "    query_set = []\n",
        "\n",
        "    for cls in selected_classes:\n",
        "        cls_index = class_indices.index(cls)\n",
        "        cls_images = [img for img, lbl in zip(all_images, all_labels) if lbl == cls_index]\n",
        "\n",
        "        # Ensure enough samples exist\n",
        "        max_samples = len(cls_images) // 2  # Split into support/query sets\n",
        "        k_shot = min(k_shot, max_samples)\n",
        "        q_queries = min(q_queries, max_samples)\n",
        "\n",
        "        if len(cls_images) < (k_shot + q_queries):\n",
        "            raise ValueError(f\"Class {cls} has only {len(cls_images)} images, but {k_shot + q_queries} are needed.\")\n",
        "\n",
        "        sampled_images = random.sample(cls_images, k_shot + q_queries)\n",
        "        support_set.extend(sampled_images[:k_shot])\n",
        "        query_set.extend(sampled_images[k_shot:])\n",
        "\n",
        "    return support_set, query_set, selected_classes\n"
      ],
      "metadata": {
        "id": "LLauruIeJz4x"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset = load_dataset('/content/fire_detection_few_shot/test')\n",
        "support, query, classes = sample_episode(test_dataset)\n",
        "print(f\"Sampled {len(support)} support images and {len(query)} query images for {len(classes)} classes.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kvoMUqsMHuG-",
        "outputId": "579fd4de-14c4-473d-f2ac-0bff54c41a78"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 20 files belonging to 2 classes.\n",
            "Sampled 10 support images and 10 query images for 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
        "\n",
        "def evaluate_prototypical_network(dataset, feature_extractor, n_way=2, k_shot=5, q_queries=5):\n",
        "    \"\"\"Evaluates the prototypical network and computes performance metrics.\"\"\"\n",
        "\n",
        "    # Sample an episode\n",
        "    support_set, query_set, selected_classes = sample_episode(dataset, n_way, k_shot, q_queries)\n",
        "\n",
        "    # Convert images to tensors\n",
        "    support_images = tf.stack(support_set)\n",
        "    query_images = tf.stack(query_set)\n",
        "\n",
        "    # Extract embeddings\n",
        "    support_embeddings = feature_extractor(support_images)\n",
        "    query_embeddings = feature_extractor(query_images)\n",
        "\n",
        "    # Compute class prototypes (mean embedding per class)\n",
        "    prototypes = []\n",
        "    for i in range(n_way):\n",
        "        class_support = support_embeddings[i * k_shot: (i + 1) * k_shot]  # Get support samples for class i\n",
        "        prototype = tf.reduce_mean(class_support, axis=0)  # Compute mean embedding\n",
        "        prototypes.append(prototype)\n",
        "\n",
        "    prototypes = tf.stack(prototypes)  # Shape: (n_way, embedding_dim)\n",
        "\n",
        "    # Compute Euclidean distances from query embeddings to prototypes\n",
        "    distances = tf.norm(query_embeddings[:, None, :] - prototypes[None, :, :], axis=-1)  # Shape: (num_queries, n_way)\n",
        "\n",
        "    # Assign each query to the nearest prototype\n",
        "    predictions = tf.argmin(distances, axis=-1).numpy()  # Convert tensor to NumPy\n",
        "    true_labels = np.concatenate([[i] * q_queries for i in range(n_way)])  # True labels based on episode\n",
        "\n",
        "    # Compute performance metrics\n",
        "    accuracy = accuracy_score(true_labels, predictions)\n",
        "    precision = precision_score(true_labels, predictions, average=\"weighted\", zero_division=0)\n",
        "    recall = recall_score(true_labels, predictions, average=\"weighted\", zero_division=0)\n",
        "    f1 = f1_score(true_labels, predictions, average=\"weighted\", zero_division=0)\n",
        "\n",
        "    # Print detailed classification report\n",
        "    print(f\"Evaluation Results (n_way={n_way}, k_shot={k_shot}, q_queries={q_queries}):\")\n",
        "    print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
        "    print(f\"Precision: {precision:.4f}\")\n",
        "    print(f\"Recall: {recall:.4f}\")\n",
        "    print(f\"F1-score: {f1:.4f}\")\n",
        "    print(\"\\nClassification Report:\")\n",
        "    print(classification_report(true_labels, predictions, target_names=selected_classes, zero_division=0))\n",
        "\n",
        "    return accuracy, precision, recall, f1\n"
      ],
      "metadata": {
        "id": "4gzcRm4FKSmr"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset\n",
        "test_dataset = load_dataset('/content/fire_detection_few_shot/test')\n",
        "\n",
        "# Create feature extractor\n",
        "feature_extractor = create_feature_extractor()  # Ensure this function is defined\n",
        "\n",
        "# Evaluate\n",
        "evaluate_prototypical_network(test_dataset, feature_extractor, n_way=2, k_shot=5, q_queries=5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8LqpxqptKWWi",
        "outputId": "f9aa9ae6-1e05-4aeb-9c3e-86de0e8c2814"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 20 files belonging to 2 classes.\n",
            "Evaluation Results (n_way=2, k_shot=5, q_queries=5):\n",
            "Accuracy: 100.00%\n",
            "Precision: 1.0000\n",
            "Recall: 1.0000\n",
            "F1-score: 1.0000\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     No_Fire       1.00      1.00      1.00         5\n",
            "        Fire       1.00      1.00      1.00         5\n",
            "\n",
            "    accuracy                           1.00        10\n",
            "   macro avg       1.00      1.00      1.00        10\n",
            "weighted avg       1.00      1.00      1.00        10\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1.0, 1.0, 1.0, 1.0)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    }
  ]
}